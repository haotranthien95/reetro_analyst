"""
FastAPI app to upload Excel files and insert rows into a PostgreSQL table `orders`.
- Columns are mapped strictly by position (left→right) starting from `ma_dat_hang` (no header mapping).
- `id` is NOT provided by Excel (generated by DB default).
- Optional override behavior based on chosen key fields (default: ma_dat_hang,ma_hang).
- Stats API: sum of `thanh_tien` per day-of-month in a date range.

Run locally:
1) Python 3.10+
2) `pip install -r requirements.txt`
3) Set env: DATABASE_URL=postgresql://user:pass@host:5432/dbname
   Optional: OVERRIDE_KEY_FIELDS="ma_dat_hang,ma_hang"
4) `uvicorn main:app --reload --port 8000`

Example:
- Upload page: http://localhost:8000/
- Stats API:   GET /api/stats/daily?start=2025-08-01&end=2025-08-31

requirements.txt (install these):
fastapi
uvicorn
pandas
openpyxl
psycopg[binary]
python-multipart
pydantic
"""
from __future__ import annotations

import os
from datetime import datetime, date
from decimal import Decimal, InvalidOperation
from typing import Any, Dict, List, Optional, Sequence, Tuple

import pandas as pd
from fastapi import FastAPI, File, Form, HTTPException, Query, UploadFile
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import psycopg
from psycopg.rows import dict_row

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@localhost:5432/postgres")
# Comma-separated list of field names used to check/perform overrides.
OVERRIDE_KEY_FIELDS = os.getenv("OVERRIDE_KEY_FIELDS", "ma_dat_hang,ma_hang").split(",")
OVERRIDE_KEY_FIELDS = [f.strip() for f in OVERRIDE_KEY_FIELDS if f.strip()]

# Strict column order for the Excel file → DB (excluding `id`)
COLUMNS_ORDER: List[str] = [
    "ma_dat_hang",
    "ma_hoa_don",
    "ma_van_don",
    "dia_chi_lay_hang",
    "thoi_gian",
    "thoi_gian_tao",
    "ma_khach_hang",
    "ten_khach_hang",
    "dien_thoai",
    "dia_chi_khach_hang",
    "khu_vuc",
    "phuong_xa",
    "nguoi_nhan_dat",
    "kenh_ban",
    "nguoi_tao",
    "doi_tac_giao_hang",
    "nguoi_nhan",
    "dien_thoai_nguoi_nhan",
    "dia_chi_nguoi_nhan",
    "khu_vuc_nguoi_nhan",
    "xa_phuong_nguoi_nhan",
    "dich_vu",
    "trong_luong",
    "dai",
    "rong",
    "cao",
    "phi_tra_doi_tac_giao_hang",
    "ghi_chu",
    "tong_tien_hang",
    "giam_gia_phieu_dat",
    "thu_khac",
    "khach_da_tra",
    "tien_mat",
    "the",
    "chuyen_khoan",
    "vi",
    "diem",
    "don_vi_tinh",
    "thoi_gian_giao_hang",
    "trang_thai",
    "ma_hang",
    "ma_vach",
    "ten_hang",
    "thuong_hieu",
    "ghi_chu_hang_hoa",
    "so_luong",
    "don_gia",
    "giam_gia_pham_tram",
    "giam_gia",
    "gia_ban",
    "thanh_tien",
]

# Data type hints for conversions
INT_COLS = {"trong_luong", "dai", "rong", "cao", "diem", "so_luong"}
DEC_COLS = {
    "phi_tra_doi_tac_giao_hang",
    "tong_tien_hang",
    "giam_gia_phieu_dat",
    "thu_khac",
    "khach_da_tra",
    "tien_mat",
    "the",
    "chuyen_khoan",
    "vi",
    "don_gia",
    "giam_gia_pham_tram",
    "giam_gia",
    "gia_ban",
    "thanh_tien",
}
TS_COLS = {"thoi_gian", "thoi_gian_tao", "thoi_gian_giao_hang"}

# -----------------------------------------------------------------------------
# App setup
# -----------------------------------------------------------------------------
app = FastAPI(title="Excel → PostgreSQL (orders)", version="1.0.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global connection pool
pool: Optional[psycopg.Connection] = None


@app.on_event("startup")
def startup() -> None:
    global pool
    try:
        pool = psycopg.connect(DATABASE_URL, autocommit=False, row_factory=dict_row)
    except Exception as e:
        raise RuntimeError(f"Failed to connect to DB: {e}")


@app.on_event("shutdown")
def shutdown() -> None:
    global pool
    if pool is not None:
        pool.close()
        pool = None


# -----------------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------------

def _is_na(v: Any) -> bool:
    return v is None or (isinstance(v, float) and pd.isna(v)) or (isinstance(v, str) and v.strip() == "")


def _to_int(v: Any) -> Optional[int]:
    if _is_na(v):
        return None
    try:
        if isinstance(v, float):
            return int(v)
        if isinstance(v, str):
            v = v.replace(",", "").strip()
            if v == "":
                return None
            return int(float(v))  # handle "123.0"
        return int(v)
    except Exception:
        return None


def _to_dec(v: Any) -> Optional[Decimal]:
    if _is_na(v):
        return None
    try:
        if isinstance(v, Decimal):
            return v
        if isinstance(v, (int, float)):
            return Decimal(str(v))
        if isinstance(v, str):
            cleaned = v.replace(" ", "").replace(",", "")
            return Decimal(cleaned)
    except (InvalidOperation, ValueError):
        return None
    return None


def _to_ts(v: Any) -> Optional[datetime]:
    if _is_na(v):
        return None
    try:
        # pandas handles Excel serials/strings
        ts = pd.to_datetime(v, errors="coerce")
        if pd.isna(ts):
            return None
        if isinstance(ts, pd.Timestamp):
            return ts.to_pydatetime().replace(tzinfo=None)
        return None
    except Exception:
        return None


def _to_text(v: Any) -> Optional[str]:
    if _is_na(v):
        return None
    s = str(v).strip()
    return s if s != "" else None


def convert_row(raw: Sequence[Any]) -> Dict[str, Any]:
    """Map a raw row (list/tuple) to a dict of column→value with conversions."""
    row_dict: Dict[str, Any] = {}
    # Normalize length: trim or pad with None
    data = list(raw[: len(COLUMNS_ORDER)]) + [None] * max(0, len(COLUMNS_ORDER) - len(raw))

    for col, v in zip(COLUMNS_ORDER, data):
        if col in INT_COLS:
            row_dict[col] = _to_int(v)
        elif col in DEC_COLS:
            row_dict[col] = _to_dec(v)
        elif col in TS_COLS:
            row_dict[col] = _to_ts(v)
        else:
            row_dict[col] = _to_text(v)
    return row_dict


def build_where_clause(key_fields: List[str]) -> str:
    if not key_fields:
        raise ValueError("OVERRIDE_KEY_FIELDS must not be empty")
    return " AND ".join([f"{f} = %({f})s" for f in key_fields])


INSERT_SQL = f"""
INSERT INTO public.orders (
    {', '.join(COLUMNS_ORDER)}
) VALUES (
    {', '.join([f'%({c})s' for c in COLUMNS_ORDER])}
)
"""

# -----------------------------------------------------------------------------
# Routes
# -----------------------------------------------------------------------------
@app.get("/", response_class=HTMLResponse)
async def upload_form() -> str:
    key_fields = ", ".join(OVERRIDE_KEY_FIELDS)
    return f"""
    <html>
      <head><title>Upload Excel to orders</title></head>
      <body>
        <h2>Upload Excel (.xlsx) → public.orders</h2>
        <p><b>Column mapping:</b> Strict by position starting from <code>ma_dat_hang</code> to <code>thanh_tien</code>. No headers are read.</p>
        <p><b>Override key fields:</b> {key_fields}</p>
        <form action="/upload-excel" method="post" enctype="multipart/form-data">
          <input type="file" name="file" accept=".xlsx" required />
          <label style="margin-left:12px;">
            <input type="checkbox" name="override" value="true" /> Override existing rows (by key fields)
          </label>
          <button type="submit">Upload</button>
        </form>
      </body>
    </html>
    """


@app.post("/upload-excel")
async def upload_excel(
    file: UploadFile = File(...),
    override: Optional[str] = Form(None),
):
    if not file.filename.lower().endswith(".xlsx"):
        raise HTTPException(status_code=400, detail="Please upload a .xlsx Excel file")

    try:
        # Read without headers, use all cells in order
        df = pd.read_excel(file.file, header=None, engine="openpyxl")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to read Excel: {e}")

    # Drop rows that are entirely NaN/empty
    df = df.dropna(how="all")

    if df.empty:
        return JSONResponse({"rows_processed": 0, "inserted": 0, "skipped": 0, "replaced": 0})

    rows = df.values.tolist()
    rows_processed = 0
    inserted = 0
    skipped = 0
    replaced = 0

    key_fields = OVERRIDE_KEY_FIELDS
    where_clause = build_where_clause(key_fields)
    do_override = (override or "").lower() == "true"

    if pool is None:
        raise HTTPException(status_code=500, detail="DB pool not initialized")

    with pool.cursor() as cur:
        try:
            for raw in rows:
                rows_processed += 1
                data = convert_row(raw)

                # Require ma_dat_hang minimally
                if not data.get("ma_dat_hang"):
                    skipped += 1
                    continue

                # Prepare key dict subset
                key_values = {k: data.get(k) for k in key_fields}
                if any(v is None for v in key_values.values()):
                    # Key incomplete → treat as new insert without override check
                    cur.execute(INSERT_SQL, data)
                    inserted += 1
                    continue

                # Check existing rows with same key
                cur.execute(f"SELECT id FROM public.orders WHERE {where_clause} LIMIT 1", key_values)
                exists = cur.fetchone() is not None

                if exists:
                    if do_override:
                        # Replace: delete all matching keys then insert fresh row
                        cur.execute(f"DELETE FROM public.orders WHERE {where_clause}", key_values)
                        cur.execute(INSERT_SQL, data)
                        replaced += 1
                    else:
                        skipped += 1
                else:
                    cur.execute(INSERT_SQL, data)
                    inserted += 1
            pool.commit()
        except Exception as e:
            pool.rollback()
            raise HTTPException(status_code=500, detail=f"DB error: {e}")

    return JSONResponse(
        {
            "rows_processed": rows_processed,
            "inserted": inserted,
            "skipped": skipped,
            "replaced": replaced,
            "override_key_fields": key_fields,
        }
    )


@app.get("/api/stats/daily")
async def stats_daily(
    start: date = Query(..., description="YYYY-MM-DD"),
    end: date = Query(..., description="YYYY-MM-DD"),
):
    if end < start:
        raise HTTPException(status_code=400, detail="end must be >= start")
    if pool is None:
        raise HTTPException(status_code=500, detail="DB pool not initialized")

    sql = """
        SELECT EXTRACT(DAY FROM thoi_gian)::int AS ngay_trong_thang,
               COALESCE(SUM(thanh_tien), 0)::text AS tong_gia_tri
        FROM public.orders
        WHERE thoi_gian >= %s AND thoi_gian < %s + INTERVAL '1 day'
        GROUP BY 1
        ORDER BY 1
    """
    # NOTE: This treats end as inclusive by adding 1 day and using < bound.

    with pool.cursor() as cur:
        cur.execute(sql, (datetime.combine(start, datetime.min.time()), datetime.combine(end, datetime.min.time())))
        rows = cur.fetchall()  # list of dicts (because row_factory=dict_row)

    # Convert Decimal to int (VND), but we kept as text to avoid float issues; cast to int if you want numeric JSON
    out = [
        {
            "ngay_trong_thang": r["ngay_trong_thang"],
            "tong_gia_tri": int(Decimal(r["tong_gia_tri"])) if r["tong_gia_tri"] is not None else 0,
        }
        for r in rows
    ]
    return out


@app.get("/healthz")
async def healthz():
    if pool is None:
        raise HTTPException(status_code=500, detail="DB pool not initialized")
    try:
        with pool.cursor() as cur:
            cur.execute("SELECT 1")
            cur.fetchone()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB error: {e}")
    return {"ok": True}
